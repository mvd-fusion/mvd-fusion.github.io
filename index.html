<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation">
    <meta name="author" content="Annoymous Submission">

    <title>MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

    <link href="assets/fontawesome-pro-6.3.0-web/css/all.min.css" rel="stylesheet">

</head>

<body>
<div class="jumbotron jumbotron-fluid">

    <div>
    <div class="container">
    <div class="row">

    
        <div class="col-sm-12" style="text-align: left;">
            <h2>MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation</h2>
            <p class="authors"> 
                <a href="https://hzhupku.github.io/" target="_blank">Hanzhe Hu</a>*<sup>1</sup>, 
                <a href="https://www.zhiz.dev/" target="_blank">Zhizhuo Zhou</a>*<sup>2</sup>, 
                <a href="https://varunjampani.github.io/" target="_blank">Varun Jampani</a><sup>3</sup>, 
                <a href="https://shubhtuls.github.io/" target="_blank">Shubham Tulsiani</a><sup>1</sup>
            </p>
            <p class="authors">* Equal contribution</p>
            <p class="authors"><sup>1</sup>Carnegie Mellon University, <sup>2</sup>Stanford University, <sup>3</sup>Stability AI</p>

            <p class="bold">CVPR 2024</b>

            <center>
            <a href="https://arxiv.org/abs/2404.03656" target="_blank" class="button icon"> Paper &nbsp<i class="far fa-book-open"></i></a> &nbsp;&nbsp;
            <a href="https://github.com/zhizdev/mvdfusion" target="_blank" class="button icon">Code &nbsp<i class="far fa-code"></i></a>  &nbsp;&nbsp;
            </center>
        </div>
        
    </div>
    </div>
    </div>
</div>


<div class="container">
    <div class="section">
        <div class="container-fluid w-85">
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/teaser_video_fps6.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
        </div>
        <div class="container-fluid w-75">
            <p>
                <span class="bold">MVD-Fusion</span> predits multi-view RGB-D images from a single input image, allowing for output to multiple 3D representations
                such as point clouds, textured meshes, and Gaussian splats. 
            </p>
        </div>
    </div>

    <div class="section">
        <div class="container-fluid w-75 rounded" style="background-color: #DDCECD;">
            <br>
            <h4>Abstract</h4>
            <p class="small">
                We introduce MVD-Fusion, a method for single-view 3D inference via generative modeling of multi-view RGB-D Images. 
                While recent methods for 3D generation uses novel-view generative models, they often require a lengthy distillation 
                process to generate a 3D output. Instead, we cast 3D inference as directly generating multiple consistent RGB-D views 
                and build upon the insight that inferring depth in addition to RGB can provide a mechanism for enforcing 3D consistency. 
                Our method is able to train on both synthetic data, Objaverse, and real-world data, CO3D. We demonstrate the generalization 
                of our model on both real and generated in-the-wild images.
            </p>
            <br>
        </div>
    </div>


    <div class="section">
        <div class="container-fluid w-75">
            <h3>Results on the Objaverse</h3>
            <p>
            We compare our method against Zero-1-to-3 and SyncDreamer on the Objaverse test set. Our results are more consistent than Zero-1-to-3 and more realistic than SyncDreamer. 
            </p>
        </div>
        <div class="container-fluid w-75">
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="70%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/obja_compare.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
        </div>
    </div>

    <div class="section">
        <div class="container-fluid w-75">
            <h3>Results on the Google Scanned Object (GSO)</h3>
            <p>
                We compare our method with Zero-1-to-3 and SyncDreamer, and visualize the input image, and multi-view images generated by each
    method as well as the ground-truth.
            </p>
        </div>
        <div class="container-fluid w-75">
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="70%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/gso_compare.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
        </div>
    </div>

    <div class="section">
        <div class="container-fluid w-75">
            <h3>Results of RGB-D Diffusion</h3>
            <p>
                We show full RGB-D results with our predicted low-resolution depth map.
            </p>
        </div>

        <div class="container-fluid w-75">
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/depth.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
        </div>
    </div>

    <div class="section">
        <div class="container-fluid w-75">
        <h3>More Results</h3>
        </div>
        
        <div class="container-fluid w-75">
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/more_video.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
        </div>
    </div>


    <div class="section">
        <div class="container-fluid w-75">
        <h3>Citation</h3>
        <p>If you found this work is useful in your own research, please considering citing the following.</p>
        <pre class="rounded">
        <code>
    @inproceedings{hu2024mvdfusion,
        title={MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation}, 
        author={Hanzhe Hu and Zhizhuo Zhou and Varun Jampani and Shubham Tulsiani},
        booktitle={CVPR},
        year={2024}
    }</code>
        </pre>
        </div>
    </div> 

    <div class="section" style="margin-bottom: 1rem;">
        <div class="container-fluid w-75">
        <h4>Acknowledgements</h4>
        <p class="small">We thank Bharath Raj, Jason Y. Zhang, Yufei (Judy) Ye, Yanbo Xu, and Zifan Shi for helpful discussions and feedback. This work is supported in part by NSF GRFP Grant No. (DGE1745016, DGE2140739).</p>
        </div>
    </div> 

</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
<footer>
    <div class="container">
        <p class="tiny"> Webpage template inspired by Shikun Liu.</p>
    </div>
</footer>

</html>
