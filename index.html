<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation">
    <meta name="author" content="Annoymous Submission">

    <title>MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation</h2>
    <h3></h3>
    <hr>
    <p class="authors">
       In Submission
    </p>
</div>


<div class="container">
    <div class="section">
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/teaser_video.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
        <p>
            We present MVD-Fusion: a method for single-view 3D inference via generative modeling of multi-view-consistent RGB-D images. While recent methods pursuing 3D inference advocate learning novel-view generative models, these generations are not 3D-consistent and require a distillation process to generate a 3D output. We instead cast the task of 3D inference as that of directly generating mutually-consistent multiple views, and we build on the insight that additionally inferring depth can provide a mechanism for enforcing this consistency.  Specifically, we train a denoising diffusion model to generate multi-view RGB-D images given a single RGB input image and leverage the (intermediate noisy) depth estimates to obtain reprojection-based conditioning for enabling multi-view consistency. We train our system using a large-scale synthetic dataset, and evaluate our approach on both, synthetic and real-world data. We demonstrate that our approach can yield more accurate synthesis compared to recent state-of-the-art, including distillation-based 3D inference and prior multi-view generation methods. We also evaluate the geometry induced by our multi-view depth prediction and find that it yields a more accurate representation than other direct 3D inference approaches. 
        </p>
    </div>


    <div class="section">
        <h2>Results on the Objaverse Dataset</h2>
        <hr>
        <p>
            We compare our method with Zero-1-to-3 and SyncDreamer, and visualize the input image, and multi-view images generated by each
method as well as the ground-truth.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="70%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/obja_video.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
    </div>

    <div class="section">
        <h2>Results on the Google Scanned Object (GSO) Dataset</h2>
        <hr>
        <p>
            We compare our method with Zero-1-to-3 and SyncDreamer, and visualize the input image, and multi-view images generated by each
method as well as the ground-truth.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="70%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/gso_video.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
    </div>

    <div class="section">
        <h2>Results of RGB-D Diffusion</h2>
        <hr>
        <p>
            We show some results of RGB-D diffusion on the Objaverse test set.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/depth_video.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
    </div>

    <div class="section">
        <h2>More Results</h2>
        <hr>
        <p>
        
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/more_video.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
    </div>


    <hr>

</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
